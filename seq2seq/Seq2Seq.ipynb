{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c31e51",
   "metadata": {},
   "source": [
    "Seq2Seq paper review & tensorflow implementation\n",
    "\n",
    "- DSL 논문 스터디 6기 손예진님이 발제하신 내용을 기반으로 작성했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4769b4c",
   "metadata": {},
   "source": [
    "## <span style = \"color : blue\"> Introduction </span>\n",
    "\n",
    "**Seq2seq** neural network model encodes an input sequence, converts it as a fixed-length vector representation, and decodes it to produce an output sequence. <br> <br>\n",
    "Seq2seq is commonly used to translate **sequence data** such as <br>\n",
    "*Machine Translation, Speech Recognition,* and *QA.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61981d05",
   "metadata": {},
   "source": [
    "### <span style = \"color : skyblue\"> Model Architecture </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d0996d",
   "metadata": {},
   "source": [
    "<img src = 'week1/2.png' width = '300'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09999a8",
   "metadata": {},
   "source": [
    "**Seq2seq** model is consisted of two major LSTM architectures: <br>\n",
    "\n",
    "> **Encoder Architecture** <br>\n",
    "> **Decoder Architecture**\n",
    "\n",
    "**Encoder cell** inputs tokenized sequence data and summerizes it into one single hidden-state numerical vector (the **context vector**) <br>\n",
    "<br>\n",
    "**Decoder cell** receives the context vector and predicts the probability of $y_t$ given the value of the hidden LSTM cell $t-1$ and input vector $t$ until the end of sentence **\\<EOS>** token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac22b0",
   "metadata": {},
   "source": [
    "## <span style = \"color : blue\"> Paper Review </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc9033",
   "metadata": {},
   "source": [
    "<img src = 'week1/1.png' width = '600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e74ce",
   "metadata": {},
   "source": [
    "To summarize, **Seq2seq model** utilizes depth-4 lstm model. Each layer contains over 1,000 cells and 1,000 dimensional word embeddings. <br> <br>\n",
    "\n",
    "Its **input vocab** is 160,000 sized, and **output vocab** is 80,000 sized vectors. <br> <br>\n",
    "\n",
    "The model used a **naive softmax** onto each 80,000 vocabs on every outputs. <br ><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d78ddcd",
   "metadata": {},
   "source": [
    "### <span style = \"color : skyblue\"> Reversed Source Sentences </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b3fb89",
   "metadata": {},
   "source": [
    "<img src = 'week1/3.png' width = '600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280bc85f",
   "metadata": {},
   "source": [
    "Seq2seq model also experiemnted an **reversed** **src** (source) sentences. When the source sentences are reversed and the **tgt** (target) sentences remain the same, the distance between the initial src token and the tgt token become closer.\n",
    "<br> <br>\n",
    "This has a significan impact since the Seq2seq model decodes data based on **sequential data** hidden state $t-1$ and input vector $t$. Since the prediction accuracy of the initial vectors improved, the overall performance also gained more accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad201598",
   "metadata": {},
   "source": [
    "<img src = 'week1/4.png' width = '600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b57acdf",
   "metadata": {},
   "source": [
    "### <span style = \"color : skyblue\"> Experimental Results </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af50bf",
   "metadata": {},
   "source": [
    "The **experimental Results** are summarized as followed.\n",
    "<br> <br>\n",
    "The **BLEU score** evaluates the quality of text generated by machine translation systems. It compares the generated text to human translated text by calculating the **n-gram overlap.**\n",
    "<br><br>\n",
    "**Seq2seq** LSTM model shows *remarkable improvement* from traditional machine translation models although it is way more **cheaper** than these SMTs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab9cf5",
   "metadata": {},
   "source": [
    "### <span style = \"color : skyblue\"> Limitations & Improvements </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff693d0",
   "metadata": {},
   "source": [
    "**Seq2seq** model has **two** major probelems.\n",
    "<br><br>\n",
    "> 1. The Encoder cell summarizes all its information into a single context vector. It results in significant **information loss.** <br>\n",
    "> 2. LSTM is a RNN model. So, it has its chronic problem: **vanishing gradient**.\n",
    "\n",
    "<br>\n",
    "\n",
    "The first problem of Seqseq model, which comes from summerizing information into a single vector, is improved on the next model : **attention + Seq2seq** which will be covered at the **next post.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22aa0d2",
   "metadata": {},
   "source": [
    "## <span style = \"color : blue\"> Model Implementation </span>\n",
    "\n",
    "Seq2seq architecture can be implemented in virtual environments by using **tensorflow keras** model. <br>\n",
    "I have constructed a simple **Seq2seq character-level neural machine translation** from the famous public-data ***\"fra-eng.zip\"*** <br> <br>\n",
    "Source : https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html <br>\n",
    "Download link: http://www.manythings.org/anki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00264dd7",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import urllib3\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32128c38",
   "metadata": {},
   "source": [
    "```python\n",
    "lines = pd.read_csv('fra.txt', names = ['src', 'tar', 'lic'], sep = '\\t')\n",
    "del lines['lic']\n",
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[0:50000]\n",
    "# <sos> -> \\t, <eos> -> \\n\n",
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "\n",
    "print('# of all samples :',len(lines))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a2d8a3",
   "metadata": {},
   "source": [
    "```python\n",
    "lines.sample(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f1f1f3",
   "metadata": {},
   "source": [
    "|**src**|tar|\n",
    "|:---:|---|\n",
    "|School is over now.|L'école est finie, désormais.|\n",
    "|You're remarkable.\t|Tu es remarquable.|\n",
    "|We'll be neighbors.|Nous serons voisins.|\n",
    "|You deserve a medal.|Tu mérites une médaille.|\n",
    "|That's what I say.|C'est ce que je dis.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ccd7e",
   "metadata": {},
   "source": [
    "### <span style = \"color : skyblue\"> Encodings & Paddings </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b95c14",
   "metadata": {},
   "source": [
    "```python\n",
    "# Define source sentence character set\n",
    "src_voc = set()\n",
    "for line in lines.src:\n",
    "    for _ in line:\n",
    "        src_voc.add(_)\n",
    "\n",
    "# Define src character set size\n",
    "src_voc_s = len(src_voc) + 1\n",
    "\n",
    "# Index each characters\n",
    "src_voc = sorted(list(src_voc))\n",
    "src_index = dict([(v, k + 1) for k, v in enumerate(src_voc)])\n",
    "\n",
    "# Encode sequence data into numerical vectors\n",
    "enc_input = []\n",
    "\n",
    "for line in lines.src:\n",
    "    enc_line = []\n",
    "    \n",
    "    for _ in line:\n",
    "        enc_line.append(src_index[_])\n",
    "        \n",
    "    enc_input.append(enc_line)\n",
    "\n",
    "# Pad src sequences\n",
    "max_src_len = max([len(line) for line in lines.src])\n",
    "enc_input = pad_sequences(enc_input, maxlen = max_src_len, padding='post')\n",
    "enc_input = to_categorical(enc_input)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45646fd",
   "metadata": {},
   "source": [
    "```python\n",
    "# Define target sentence character set\n",
    "tar_voc = set()\n",
    "for line in lines.tar:\n",
    "    for _ in line:\n",
    "        tar_voc.add(_)\n",
    "\n",
    "# Define tar character set size        \n",
    "tar_voc_s = len(tar_voc) + 1    \n",
    "\n",
    "# Index each characters\n",
    "tar_voc = sorted(list(tar_voc))\n",
    "tar_index = dict([(v, k + 1) for k, v in enumerate(tar_voc)])\n",
    "\n",
    "# encode target sentences into numerical vectors\n",
    "dec_input = []\n",
    "\n",
    "for line in lines.tar:\n",
    "    enc_line = []\n",
    "    for _ in line:\n",
    "        enc_line.append(tar_index[_])\n",
    "        \n",
    "    dec_input.append(enc_line)\n",
    "\n",
    "# encode target label sentences into numerical values\n",
    "# remove <sos> token from sentences\n",
    "dec_target = []\n",
    "\n",
    "for line in lines.tar:\n",
    "    timestep = 0\n",
    "    enc_line = []\n",
    "    for _ in line:\n",
    "        if timestep > 0:\n",
    "            enc_line.append(tar_index[_])\n",
    "            timestep += 1\n",
    "            \n",
    "    dec_target.append(enc_line)\n",
    "\n",
    "# Pad tar sequences\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "dec_input = pad_sequences(dec_input, maxlen = max_tar_len, padding = 'post')\n",
    "dec_input = to_categorical(dec_input)\n",
    "dec_target = pad_sequences(dec_target, maxlen = max_tar_len, padding = 'post')\n",
    "dec_target = to_categorical(dec_target)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c71bb",
   "metadata": {},
   "source": [
    "### <span style = \"color : skyblue\"> Train Seq2seq Machine Translation Model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a66660",
   "metadata": {},
   "source": [
    "```python\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59c453",
   "metadata": {},
   "source": [
    "```python\n",
    "# Define input sequences and LSTM layer\n",
    "enc_inputs = Input(shape= (None, src_voc_s))\n",
    "enc_lstm = LSTM(units = 256, return_state = True)\n",
    "\n",
    "# output of LSTM layer\n",
    "enc_outputs, state_h, state_c = enc_lstm(enc_inputs)\n",
    "\n",
    "# context vector holds two states: hidden-state, cell-state\n",
    "# Handle over these information to the decoder\n",
    "context_vector = [state_h, state_c]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1908f49d",
   "metadata": {},
   "source": [
    "```python\n",
    "# Define input sequences and LSTM layer\n",
    "dec_inputs = Input(shape = (None, tar_voc_s))\n",
    "dec_lstm = LSTM(units = 256, return_sequences = True, return_state = True)\n",
    "\n",
    "# Decoder uses context vector from encoder cell as an initial state\n",
    "dec_outputs, _, _= dec_lstm(dec_inputs, initial_state = context_vector)\n",
    "\n",
    "# Use softmax to compare loss\n",
    "dec_softmax = Dense(tar_voc_s, activation = 'softmax')\n",
    "dec_outputs = dec_softmax(dec_outputs)\n",
    "\n",
    "# Define checkpoint for best model\n",
    "checkpoint_path = 'my_checkpoint.ckpt'\n",
    "\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, \n",
    "                             save_weights_only=True, \n",
    "                             save_best_only=True, \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "# Define & Train model\n",
    "model = Model([enc_inputs, dec_inputs], dec_outputs)\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\")\n",
    "history = model.fit(x=[enc_input, dec_input],\n",
    "                    y = dec_target,\n",
    "                    batch_size = 64,\n",
    "                    validation_split = 0.2,\n",
    "                    callbacks = [checkpoint],\n",
    "                    epochs = epochs)\n",
    "\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "model.save(\"english-french-mtl.h5\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f37bcf8",
   "metadata": {},
   "source": [
    "### <span style = \"color : skyblue\"> Evaluate Seq2seq Machine Translation Model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be12d6",
   "metadata": {},
   "source": [
    "```python\n",
    "# Define Encoder\n",
    "enc_model = Model(inputs = enc_inputs, outputs = context_vector)\n",
    "\n",
    "# Define Decoder\n",
    "dec_input_h = Input(shape=(256, ))\n",
    "dec_input_c = Input(shape=(256, ))\n",
    "dec_s_inputs = [dec_input_h, dec_input_c]\n",
    "\n",
    "# Use t-1 cell and hidden state to predict next t cell\n",
    "dec_outputs, state_h, state_c = dec_lstm(dec_inputs, initial_state = dec_s_inputs)\n",
    "\n",
    "dec_states = [state_h, state_c]\n",
    "dec_outputs = dec_softmax(dec_outputs)\n",
    "dec_model = Model(inputs = [dec_inputs] + dec_s_inputs,\n",
    "                  outputs = [dec_outputs] + dec_states)\n",
    "\n",
    "# get vocab from index\n",
    "index_to_src = dict((i, char) for char, i in src_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_index.items())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8bf97",
   "metadata": {},
   "source": [
    "```python\n",
    "def dec_sequence(input_seq):\n",
    "    states_value = enc_model.predict(input_seq)\n",
    "    \n",
    "    # create one-hot vector for <sos> token\n",
    "    target_seq = np.zeros((1, 1, tar_voc_s))\n",
    "    target_seq[0, 0, tar_index['\\t']] = 1.\n",
    "    \n",
    "    stop_condition = False\n",
    "    dec_sentence = \"\"\n",
    "    \n",
    "    # Run through iteration until stop_condition becomes TRUE\n",
    "    while not stop_condition:\n",
    "        # Use hidden-state + t-1 cell to predict t cell\n",
    "        output_tokens, h, c = dec_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        # tokenize predictions into word sequence\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # Append predicted word into decoded sentence\n",
    "        dec_sentence += sampled_char\n",
    "\n",
    "        # If dec-sentence reaches <eos>, break the iteration.<eos>\n",
    "        if (sampled_char == '\\n' or\n",
    "            len(dec_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "\n",
    "    # Save t cell\n",
    "    target_seq = np.zeros((1, 1, tar_voc_s))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "    # Save hidden state\n",
    "    states_value = [h, c]\n",
    "    \n",
    "    return dec_sentence\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df9b7a4",
   "metadata": {},
   "source": [
    "```python\n",
    "for _ in [3, 50]:\n",
    "    seq = enc_input[_: _ + 1]\n",
    "    dec_sentence = dec_sequence(seq)\n",
    "    print('-' * 35)\n",
    "    print('input sentence: ', lines.src[_])\n",
    "    # print without \\t and \\n\n",
    "    print('answer sentence: ', lines.tar[_][2:len(lines.tar[_]) - 1])\n",
    "    # print without \\n\n",
    "    print('translated sentence: ', dec_sentence[1: len(dec_sentence) - 1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065054a8",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "입력 문장: Hi. <br>\n",
    "정답 문장: Salut ! <br>\n",
    "번역 문장: Salut. <br>\n",
    "-----------------------------------\n",
    "입력 문장: I see. <br>\n",
    "정답 문장: Aha. <br>\n",
    "번역 문장: Je change. <br>\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4787806",
   "metadata": {},
   "source": [
    "출처: 딥러닝을 이용한 자연어 처리 입문 https://wikidocs.net/24996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55e272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
